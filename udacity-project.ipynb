{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "ws = Workspace.get(name=\"quick-starts-ws-128336\")\n",
        "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: quick-starts-ws-128336\n",
            "Azure region: southcentralus\n",
            "Subscription id: 7395406a-64a8-4774-b0c2-0d5dafb2a8ce\n",
            "Resource group: aml-quickstarts-128336\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1606654870885
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "\n",
        "# TODO: Create compute cluster\n",
        "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
        "# max_nodes should be no greater than 4.\n",
        "\n",
        "cluster_name = \"hrcluster\"\n",
        "compute_config = AmlCompute.provisioning_configuration(vm_size = \"Standard_D2_V2\", max_nodes = 4)\n",
        "cpu_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "cpu_cluster.wait_for_completion(show_output = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1606654876350
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform, choice\n",
        "import os\n",
        "\n",
        "# Specify parameter sampler\n",
        "ps = RandomParameterSampling({\n",
        "    \"--C\":uniform(0.0, 1.5),\n",
        "    \"--max_iter\":choice(100, 200, 300, 600)\n",
        "})\n",
        "\n",
        "# Specify a Policy\n",
        "policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)\n",
        "\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "\n",
        "# Create a SKLearn estimator for use with train.py\n",
        "est = SKLearn(source_directory = \".\", entry_script=\"train.py\", compute_target = cpu_cluster)\n",
        "\n",
        "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
        "hyperdrive_config = HyperDriveConfig(estimator = est, hyperparameter_sampling = ps, policy = policy, primary_metric_goal = PrimaryMetricGoal.MAXIMIZE, primary_metric_name = \"Accuracy\", max_total_runs = 10, max_concurrent_runs = 4)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1606654933137
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
        "hyperdrive_run = exp.submit(config=hyperdrive_config)\n",
        "RunDetails(hyperdrive_run).show()"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1606654120339
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Get your best run and save the model from that run.\n",
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "parameter_values = best_run.get_details()['runDefinition']['arguments']\n",
        "print('Best Run Id: ', best_run.id)\n",
        "print('\\n Accuracy: ', best_run_metrics['Accuracy'])\n",
        "print('\\n Regularization Strength: ', parameter_values[1])\n",
        "print('\\n Max Iterations: ', parameter_values[3])\n",
        "joblib.dump(value = parameter_values, filename='hyperdrive_model.joblib')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Run Id:  HD_d16826d7-3908-4419-953f-c54d1e4c9bd9_0\n",
            "\n",
            " Accuracy:  0.910152657715652\n",
            "\n",
            " Regularization Strength:  0.28071377292087485\n",
            "\n",
            " Max Iterations:  300\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "['hyperdrive_model.joblib']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1606655674532
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "\n",
        "ds = TabularDatasetFactory.from_delimited_files(\n",
        "    \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1606655748456
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from train import clean_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use the clean_data function to clean your data.\n",
        "x, y = clean_data(ds)\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.33, random_state=42)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1606655768179
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Set parameters for AutoMLConfig\n",
        "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
        "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
        "# Azure tenant, which will incur personal costs.\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task='classification',\n",
        "    primary_metric='accuracy',\n",
        "    training_data=ds,\n",
        "    label_column_name=\"y\",\n",
        "    n_cross_validations=5,\n",
        "    compute_target = cpu_cluster)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1606656244357
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your automl run\n",
        "automl_run = exp.submit(automl_config, show_output=True)   \n",
        "from azureml.widgets import RunDetails\n",
        "RunDetails(automl_run).show()\n",
        "automl_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on remote.\n",
            "Running on remote compute: hrcluster\n",
            "Parent Run ID: AutoML_89248bfe-0dfb-416b-b14a-d6ee0349824a\n",
            "\n",
            "Current status: FeaturesGeneration. Generating features for the dataset.\n",
            "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
            "Current status: DatasetBalancing. Performing class balancing sweeping\n",
            "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
            "Current status: ModelSelection. Beginning model selection.\n",
            "\n",
            "****************************************************************************************************\n",
            "DATA GUARDRAILS: \n",
            "\n",
            "TYPE:         Class balancing detection\n",
            "STATUS:       ALERTED\n",
            "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
            "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
            "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
            "+---------------------------------+---------------------------------+--------------------------------------+\n",
            "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
            "+=================================+=================================+======================================+\n",
            "|3692                             |yes                              |32950                                 |\n",
            "+---------------------------------+---------------------------------+--------------------------------------+\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         Missing feature values imputation\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  No feature missing values were detected in the training data.\n",
            "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         High cardinality feature detection\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
            "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "****************************************************************************************************\n",
            "ITERATION: The iteration being evaluated.\n",
            "PIPELINE: A summary description of the pipeline being evaluated.\n",
            "DURATION: Time taken for the current iteration.\n",
            "METRIC: The result of computing score on the fitted pipeline.\n",
            "BEST: The best observed score thus far.\n",
            "****************************************************************************************************\n",
            "\n",
            " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
            "         0   MaxAbsScaler LightGBM                          0:00:15       0.9153    0.9153\n",
            "         1   MaxAbsScaler XGBoostClassifier                 0:00:02       0.9151    0.9153\n",
            "         2   MaxAbsScaler RandomForest                      0:00:37       0.8935    0.9153\n",
            "         3   MaxAbsScaler RandomForest                      0:00:39       0.8880    0.9153\n",
            "         4   MaxAbsScaler SGD                               0:00:39       0.8602    0.9153\n",
            "         5   MaxAbsScaler SGD                               0:00:50       0.9069    0.9153\n",
            "         6   MaxAbsScaler ExtremeRandomTrees                0:00:44       0.8998    0.9153\n",
            "         7   MaxAbsScaler ExtremeRandomTrees                0:00:43       0.8997    0.9153\n",
            "         8   MaxAbsScaler ExtremeRandomTrees                0:00:42       0.8991    0.9153\n",
            "         9   MaxAbsScaler ExtremeRandomTrees                0:00:34       0.7514    0.9153\n",
            "        10   MaxAbsScaler SGD                               0:00:36       0.9036    0.9153\n",
            "        11   MaxAbsScaler SGD                               0:00:04       0.9038    0.9153\n",
            "        12   MaxAbsScaler RandomForest                      0:00:36       0.8893    0.9153\n",
            "        13   StandardScalerWrapper ExtremeRandomTrees       0:00:35       0.8880    0.9153\n",
            "        14   MaxAbsScaler RandomForest                      0:00:37       0.7779    0.9153\n",
            "        15   MaxAbsScaler SGD                               0:00:24       0.8521    0.9153\n",
            "        16   MaxAbsScaler RandomForest                      0:00:19       0.8880    0.9153\n",
            "        17   MaxAbsScaler ExtremeRandomTrees                0:00:37       0.8997    0.9153\n",
            "        18   SparseNormalizer ExtremeRandomTrees            0:00:42       0.7228    0.9153\n",
            "        19   MaxAbsScaler SGD                               0:00:34       0.9063    0.9153\n",
            "        20   MaxAbsScaler ExtremeRandomTrees                0:00:39       0.7565    0.9153\n",
            "        21   MaxAbsScaler RandomForest                      0:00:32       0.7680    0.9153\n",
            "        22   MaxAbsScaler LightGBM                          0:00:32       0.9073    0.9153\n",
            "        23   MaxAbsScaler RandomForest                      0:00:38       0.8880    0.9153\n",
            "        24   MaxAbsScaler LightGBM                          0:00:50       0.9115    0.9153\n",
            "        25   MaxAbsScaler LightGBM                          0:00:34       0.8880    0.9153\n",
            "        26                                                  0:00:14          nan    0.9153\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\n",
        "best_automl_run, best_model = automl_run.get_output()\n",
        "joblib.dump(value = best_model, filename='automl_model.joblib')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "['automl_model.joblib']"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1606659412105
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete compute cluster\n",
        "cpu_cluster.delete()"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1606660082068
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}